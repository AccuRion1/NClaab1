{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c08b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF для документа 1:\n",
      "  машинное: 0.2500\n",
      "  обучение: 0.2500\n",
      "  интересная: 0.2500\n",
      "  область: 0.2500\n",
      "\n",
      "IDF для всех слов:\n",
      "  nlp: 1.0986\n",
      "  аспект: 1.0986\n",
      "  интересная: 1.0986\n",
      "  ключевой: 1.0986\n",
      "  машинного: 1.0986\n",
      "  машинное: 1.0986\n",
      "  машинным: 1.0986\n",
      "  область: 0.4055\n",
      "  обучение: 0.4055\n",
      "  обучением: 1.0986\n",
      "  обучения: 1.0986\n",
      "  с: 0.4055\n",
      "  связана: 1.0986\n",
      "  учителем: 1.0986\n",
      "\n",
      "Расчет для слова 'машинное' в первом документе:\n",
      "  TF = 0.2500\n",
      "  IDF = 1.0986\n",
      "  TF-IDF = 0.2747\n",
      "\n",
      "Проверка:\n",
      "  Ручной расчет TF = 0.25, получено = 0.2500\n",
      "  Ручной расчет IDF = 0, получено = 1.0986\n",
      "  Ручной расчет TF-IDF = 0, получено = 0.2747\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "documents = [\n",
    "    \"машинное обучение интересная область\",\n",
    "    \"обучение с учителем ключевой аспект машинного обучения\",\n",
    "    \"область nlp связана с машинным обучением\"\n",
    "]\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in documents]\n",
    "\n",
    "def compute_tf(document):\n",
    "    word_counts = Counter(document)\n",
    "    total_words = len(document)\n",
    "    tf_dict = {}\n",
    "    for word, count in word_counts.items():\n",
    "        tf_dict[word] = count / total_words\n",
    "    return tf_dict\n",
    "\n",
    "def compute_idf(tokenized_docs):\n",
    "    num_docs = len(tokenized_docs)\n",
    "    idf_dict = {}\n",
    "    \n",
    "    all_words = set()\n",
    "    for doc in tokenized_docs:\n",
    "        all_words.update(doc)\n",
    "    \n",
    "    for word in all_words:\n",
    "        doc_count = sum(1 for doc in tokenized_docs if word in doc)\n",
    "        idf_dict[word] = math.log(num_docs / doc_count)\n",
    "    \n",
    "    return idf_dict\n",
    "\n",
    "tf_doc1 = compute_tf(tokenized_docs[0])\n",
    "print(\"TF для документа 1:\")\n",
    "for word, tf in tf_doc1.items():\n",
    "    print(f\"  {word}: {tf:.4f}\")\n",
    "\n",
    "idf_dict = compute_idf(tokenized_docs)\n",
    "print(\"\\nIDF для всех слов:\")\n",
    "for word, idf in sorted(idf_dict.items()):\n",
    "    print(f\"  {word}: {idf:.4f}\")\n",
    "\n",
    "word = \"машинное\"\n",
    "tf_idf = tf_doc1.get(word, 0) * idf_dict.get(word, 0)\n",
    "\n",
    "print(f\"\\nРасчет для слова '{word}' в первом документе:\")\n",
    "print(f\"  TF = {tf_doc1[word]:.4f}\")\n",
    "print(f\"  IDF = {idf_dict[word]:.4f}\")\n",
    "print(f\"  TF-IDF = {tf_idf:.4f}\")\n",
    "\n",
    "print(f\"\\nПроверка:\")\n",
    "print(f\"  Ручной расчет TF = 0.25, получено = {tf_doc1[word]:.4f}\")\n",
    "print(f\"  Ручной расчет IDF = 0, получено = {idf_dict[word]:.4f}\")\n",
    "print(f\"  Ручной расчет TF-IDF = 0, получено = {tf_idf:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
